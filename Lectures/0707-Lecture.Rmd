---
title: "0707-Lecture: Supervised Learning"
subtitle: "Principal component regression and partial least squares"
author: "Amber Potter"
date: "7/7/2022"
output: html_document
---
```{r setup, echo = FALSE, warning = FALSE, message = FALSE}
library(tidyverse)
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
```



## Principal component regression (PCR)

```{r out.width='50%', echo = FALSE, fig.align='center'}
knitr::include_graphics("https://bradleyboehmke.github.io/HOML/images/pcr-steps.png")
```

### Load Tidyverse

```{r}
library(tidyverse)
```


## Example data: NFL teams summary

Created dataset using [`nflfastR`](https://www.nflfastr.com/) summarizing NFL team performances from 1999 to 2021

## Load NFL Model Data

```{r, warning = FALSE, message = FALSE}
nfl_teams_data <- read_csv("http://www.stat.cmu.edu/cmsac/sure/2022/materials/data/sports/regression_examples/nfl_team_season_summary.csv")
```


## Pre-process NFL Model Data

```{r}
nfl_model_data <- nfl_teams_data %>%
  mutate(score_diff = points_scored - points_allowed) %>%
  # Only use rows with air yards
  filter(season >= 2006) %>%
  dplyr::select(-wins, -losses, -ties, -points_scored, -points_allowed, -season, -team)
nfl_model_data
```

## Save NFL Model Data

Save as csv:

```{r}
write_csv(nfl_model_data,
          "data/nfl_model_data.csv")

```

Save as RDS:

```{r}
write_rds(nfl_model_data,
          "data/nfl_model_data.rds")
```


## Read NFL Model Data

Read CSV:

nfl_model_data <- read_csv("data/nfl_model_data.csv")

Read RSD:

```{r}
nfl_model_data <- read_rds("data/nfl_model_data.rds")
```


## Implement PCR with [`pls` package](https://cran.r-project.org/web/packages/pls/vignettes/pls-manual.pdf)

Similar syntax to `lm` formula but specify the number of PCs (`ncomp`)

## Partial Least Squares

```{r pls-pcr}
library(pls)
nfl_pcr_fit <- pcr(score_diff ~ ., ncomp = 2, scale = TRUE, data = nfl_model_data)
summary(nfl_pcr_fit)
```


# Hold Out PCR Analysis

## Tuning PCR with [`caret`](http://topepo.github.io/caret/index.html)

To perform PCR __we need to tune the number of principal components__


- Tune # components in PCR with [`caret`](http://topepo.github.io/caret/index.html)

- `train` with 10-fold CV using `pcr` from [`pls`](https://cran.r-project.org/web/packages/pls/vignettes/pls-manual.pdf)

```{r caret-cv}
set.seed(2013)
library(caret)
cv_model_pcr <- train(
  score_diff ~ ., 
  data = nfl_model_data, 
  method = "pcr", #<<
  trControl = trainControl(method = "cv", number = 10), # cv = cross validation, 10 = # of folds
  preProcess = c("center", "scale"), #<<
  tuneLength = ncol(nfl_model_data) - 1)

ggplot(cv_model_pcr) + 
  theme_bw()
```



## Tuning PCR with [`caret`](http://topepo.github.io/caret/index.html)

By default returns model with minimum CV error as `finalModel`

```{r}
summary(cv_model_pcr$finalModel)
```


## Tuning PCR with [`caret`](http://topepo.github.io/caret/index.html)

Modify `selectionFunction` in `train` to be the `oneSE` rule

Chooses number of components that performs within one standard error of the minimum


```{r caret-cv-onese}
set.seed(2013)
cv_model_pcr_onese <- train(
  score_diff ~ ., 
  data = nfl_model_data, 
  method = "pcr", #<<
  trControl = 
    trainControl(method = "cv", number = 10,
                 selectionFunction = "oneSE"), #<<
  preProcess = c("center", "scale"),
  tuneLength = ncol(nfl_model_data) - 1)
```



```{r}
summary(cv_model_pcr_onese$finalModel)
```

## Partial least squares (PLS)

__PCR is agnostic of response variable__

```{r out.width='80%', echo = FALSE, fig.align='center'}
knitr::include_graphics("https://bradleyboehmke.github.io/HOML/images/pls-vs-pcr.png")
```



## PLS as supervised dimension reduction

__First principal component__ in PCA:

$$Z_1 = \phi_{11} X_1 + \phi_{21} X_2 + \dots + \phi_{p1} X_p$$


In PLS we set $\phi_{j1}$ to the coefficient from __simple linear regression__ of $Y$ on each $X_j$

  - Remember this slope is proportional to the correlation! $\widehat{\beta}_{} = r_{X,Y} \cdot \frac{s_Y}{s_X}$
  
  - Thus $Z_1$ in PLS places most weight on variables strongly related to response $Y$



To compute $Z_2$ for PLS:

  - Regress each $X_j$ on $Z_1$, residuals capture signal not explained by $Z_1$
  
  - Set $\phi_{j2}$ to the coefficient from __simple linear regression__ of $Y$ on these residuals for each variable


Repeat process until all $Z_1, Z_2, \dots, Z_p$ are computed (__PLS components__)

Then regress $Y$ on $Z_1, Z_2, \dots, Z_p^*$, where $p^* < p$ is a tuning parameter


## Tuning PLS with [`caret`](http://topepo.github.io/caret/index.html)


```{r caret-pls-cv}
set.seed(2013)
cv_model_pls <- train(
  score_diff ~ ., 
  data = nfl_model_data, 
  method = "pls", #<< only line changed from above
  trControl = 
    trainControl(method = "cv", number = 10,
                 selectionFunction = "oneSE"), 
  preProcess = c("center", "scale"),
  tuneLength = ncol(nfl_model_data) - 1)
ggplot(cv_model_pls) + theme_bw()
```

Sharp contrast with PCR results!

Fewer PLS components because they are guided by the response variable



_But how do we summarize variable relationships without a single coefficient?_


## Variable importance with [`vip` package](https://cran.r-project.org/web/packages/vip/vignettes/vip-introduction.pdf)


__Variable importance__ attempts to quantify how influential variables are in the model

  - e.g., absolute value of $t$-statistic in regression
  

__For PLS__:  weighted sums of the absolute regression coefficients across components 

  - Weights are function of reduction of RSS across the number of PLS components
  

```{r 'vip-example'}
# Check out `cv_model_pls$finalModel$coefficients`
library(vip)
vip(cv_model_pls, num_features = 10, #<<
    method = "model") + #<<
  theme_bw() 
```


## Partial dependence plots (PDP) with [`pdp` package](https://bgreenwell.github.io/pdp/index.html)

PDPs display the change in the average predicted response as the predictor varies over their marginal distribution

  - More useful for non-linear models later on!
  
```{r 'pdp-example', fig.width=8, fig.height=4, fig.align='center'}
library(pdp)
partial(cv_model_pls, "offense_total_epa_pass", plot = TRUE) #<<
```




